{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"final_vqa.ipynb","provenance":[{"file_id":"1krnF_vxA59BZL7EKhlM4naj8BO4p77CD","timestamp":1625097345094},{"file_id":"1VipQedHAPxrPlVHWQU2yJIbZ2WfTVVMK","timestamp":1624436046562}],"collapsed_sections":["ywPKRVxIGTIq","ZdHFSo1eo2Wa","CVBYOc5lcj_L"],"machine_shape":"hm","mount_file_id":"16QE0jc2jykDnV8TZtLfzutfW7_-wH6Pn","authorship_tag":"ABX9TyNXyB1wDM+KzMNrc+siL+VN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"68dd1d8e159146e98c144acf35e2bab1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_37b6d1cca09549ceb8278636f2b4b356","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_51bb95d44623466daed0cf03e25041c4","IPY_MODEL_41083dd4bee241c1a5ce0da28286973f"]}},"37b6d1cca09549ceb8278636f2b4b356":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"51bb95d44623466daed0cf03e25041c4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_817f53b566f5421aa53c476eeea5e224","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":371391,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":371391,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9d0bade193814c9aa03a485fc0f57e59"}},"41083dd4bee241c1a5ce0da28286973f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3dd0a01725b84a118323ad19158c46ef","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 371k/371k [00:00&lt;00:00, 524kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_205afb5956fe41058f03174a73a4767e"}},"817f53b566f5421aa53c476eeea5e224":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"9d0bade193814c9aa03a485fc0f57e59":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3dd0a01725b84a118323ad19158c46ef":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"205afb5956fe41058f03174a73a4767e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ea1dc37ad4ba499bbc53c8bee63490ac":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e4712765df274b2093c14959a004fe45","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_295fbb3c460f41f796619b6204325230","IPY_MODEL_c149e076482645b7adecc880ddc06ff9"]}},"e4712765df274b2093c14959a004fe45":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"295fbb3c460f41f796619b6204325230":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d1e0389644974136b9fe8b3a17d142d7","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":77779,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":77779,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fe8dcc8ff69b40ef9e81fcacf8f66fb2"}},"c149e076482645b7adecc880ddc06ff9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_38f85c08fffe44e5a7caf76cb3918ae0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 77.8k/77.8k [00:01&lt;00:00, 39.8kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_685d729ea887406abfc48a37c45d5514"}},"d1e0389644974136b9fe8b3a17d142d7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"fe8dcc8ff69b40ef9e81fcacf8f66fb2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"38f85c08fffe44e5a7caf76cb3918ae0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"685d729ea887406abfc48a37c45d5514":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3be7b74b4f66490185dff074174fc07b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a98625ea41554d33a09cfd28a96e91f0","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_dedda69195744f0993a41cc1fe051069","IPY_MODEL_f325185911dd4efe83d212180c4c45cb"]}},"a98625ea41554d33a09cfd28a96e91f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dedda69195744f0993a41cc1fe051069":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ec99a776e6d1419f97c89cc023aa17d9","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":51,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":51,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2021c34c62c44297b4958e9092666cc5"}},"f325185911dd4efe83d212180c4c45cb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_59498d3f9d37418f97eba8de0fc1693e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 51.0/51.0 [00:00&lt;00:00, 72.9B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cbbf22fdde3647daa2d3d7dfe0777299"}},"ec99a776e6d1419f97c89cc023aa17d9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2021c34c62c44297b4958e9092666cc5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"59498d3f9d37418f97eba8de0fc1693e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"cbbf22fdde3647daa2d3d7dfe0777299":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"YJEi-ho_Yfxh"},"source":["# !pip install git+https://github.com/SKT-AI/KoBART#egg=kobart\n","!pip3 install kobert-transformers\n","!pip install customized_konlpy\n","!pip install sentencepiece\n","!unzip \"./drive/My Drive/vqa/train.zip\" -d \"./\"\n","!mkdir test\n","!unzip \"./drive/My Drive/vqa/test.zip\" -d \"./test\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I1kTyammN3xA"},"source":["from tensorflow.keras.layers import Input, Dense, concatenate, Dropout, Flatten, Embedding, LayerNormalization, Reshape, Conv2D, MaxPooling2D\n","from tensorflow.keras.models import Model\n","from keras.preprocessing import image, sequence\n","from keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.utils import to_categorical, Sequence\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import keras\n","from PIL import Image\n","from kobert_transformers import get_tokenizer\n","from ckonlpy.tag import Twitter\n","from google.colab import files"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v8ZGA-pIPjZ9"},"source":["###하이퍼파라미터"]},{"cell_type":"code","metadata":{"id":"UORZMh_TPiZL"},"source":["VOCAB_SIZE = 10000\n","d_model = 256\n","max_len = 20\n","dff = 512\n","num_heads = 8\n","num_layers = 10\n","dropout = 0.05\n","EPOCHS = 10\n","BATCH_SIZE = 100\n","TARGET_SIZE = 224\n","WARM_UP = 8000"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ywPKRVxIGTIq"},"source":["###콜백\n"]},{"cell_type":"code","metadata":{"id":"IrQQ-WDpGVyQ"},"source":["callback_list = [\n","  keras.callbacks.EarlyStopping(\n","    monitor='val_accuracy', # 모델의 검증 정확도 모니터링\n","    patience=10, # 10 에포크보다 더 길게 향상되지 않으면 중단\n","  ),\n","  keras.callbacks.ModelCheckpoint(\n","    filepath='my_model.h5', # 저장\n","    monitor='val_loss',\n","    save_best_only=True, # 가장 좋은 모델\n","    save_weights_only=True\n","  )\n","]\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZdHFSo1eo2Wa"},"source":["###생략"]},{"cell_type":"code","metadata":{"id":"fjC7vMNqg-yo"},"source":["class TokenAndPositionEmbedding(tf.keras.layers.Layer):\n","    def __init__(self, max_len, vocab_size, embedding_dim):\n","        super(TokenAndPositionEmbedding, self).__init__()\n","        self.token_emb = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n","        self.pos_emb = tf.keras.layers.Embedding(max_len, embedding_dim)\n","        self.vocab_size = vocab_size\n","        self.max_len = max_len\n","        self.embedding_dim = embedding_dim\n","    \n","    def get_config(self):\n","\n","        config = super().get_config().copy()\n","        config.update({\n","            'vocab_size': self.vocab_size,\n","            'max_len': self.max_len,\n","            'embedding_dim': self.embedding_dim,\n","            'token_emb': self.token_emb,\n","            'pos_emb': self.pos_emb\n","        })\n","        return config\n","\n","    def call(self, x):\n","        max_len = tf.shape(x)[-1]\n","        positions = tf.range(start=0, limit=max_len, delta=1)\n","        positions = self.pos_emb(positions)\n","        x = self.token_emb(x)\n","        return x + positions"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l7CGwtFMinl7"},"source":["# 값으로 들어온 query, key, value를 통해 어텐션 메커니즘 수행\n","# scaled dot product 계산 \n","# 멀티헤드 어텐션을 구현하므로, d_model/num_heads의 크기를 가진다.\n","# 문장의 길이는 그 전에 제로 패딩을 통해 전부 맞춰준다.\n","# num_heads는 멀티 헤드의 개수\n","# batch_size는 훈련을 시킬 때 사용하는 배치사이즈\n","# 출력 값\n","# output : softmax 함수에 value 행렬을 곱해준 벡터\n","# attention_weights : softmax 함수까지 연산된 행렬 (어텐션 스코어 행렬?)\n","\n","def scaled_dot_product_attention(query, key, value, mask):\n","  # query 크기 : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n","  # key 크기 : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n","  # value 크기 : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n","  # padding_mask : (batch_size, 1, 1, key의 문장 길이)\n","\n","  # Q와 K의 곱. 어텐션 스코어 행렬.\n","  matmul_qk = tf.matmul(query, key, transpose_b=True)\n","\n","  # 스케일링\n","  # dk의 루트값으로 나눠준다.\n","  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n","  logits = matmul_qk / tf.math.sqrt(depth)\n","\n","  # 마스킹. 어텐션 스코어 행렬의 마스킹 할 위치에 매우 작은 음수값을 넣는다.\n","  # 매우 작은 값이므로 소프트맥스 함수를 지나면 행렬의 해당 위치의 값은 0이 된다.\n","  if mask is not None:\n","    logits += (mask * -1e9)\n","\n","  # 소프트맥스 함수는 마지막 차원인 key의 문장 길이 방향으로 수행된다.\n","  # attention weight : (batch_size, num_heads, query의 문장 길이, key의 문장 길이)\n","  attention_weights = tf.nn.softmax(logits, axis=-1)\n","\n","  # output : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n","  output = tf.matmul(attention_weights, value)\n","\n","  return output, attention_weights"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DHUKfMz9ipA-"},"source":["# 멀티헤드 어텐션을 만드는 클래스\n","\n","class MultiHeadAttention(tf.keras.layers.Layer):\n","\n","  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n","    super(MultiHeadAttention, self).__init__(name=name)\n","    self.num_heads = num_heads\n","    self.d_model = d_model\n","\n","    assert d_model % self.num_heads == 0\n","\n","    # d_model을 num_heads로 나눈 값.\n","    # 논문 기준 : 64\n","    self.depth = d_model // self.num_heads\n","\n","    # WQ, WK, WV에 해당하는 밀집층 정의\n","    self.query_dense = tf.keras.layers.Dense(units=d_model,kernel_regularizer=keras.regularizers.l2(0.001))\n","    self.key_dense = tf.keras.layers.Dense(units=d_model,kernel_regularizer=keras.regularizers.l2(0.001))\n","    self.value_dense = tf.keras.layers.Dense(units=d_model,kernel_regularizer=keras.regularizers.l2(0.001))\n","\n","    # WO에 해당하는 밀집층 정의\n","    self.dense = tf.keras.layers.Dense(units=d_model,kernel_regularizer=keras.regularizers.l2(0.001))\n","\n","  def get_config(self):\n","    config = super().get_config().copy()\n","    config.update({\n","        'd_model': self.d_model,\n","        'num_heads': self.num_heads,\n","        'depth': self.depth,\n","        'query_dense': self.query_dense,\n","        'key_dense' : self.key_dense,\n","        'value_dense': self.value_dense,\n","        'dense': self.dense\n","    })\n","    return config\n","\n","  # num_heads 개수만큼 q, k, v를 split하는 함수\n","  def split_heads(self, inputs, batch_size):\n","    inputs = tf.reshape(\n","        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n","    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n","\n","  def call(self, inputs):\n","    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n","        'value'], inputs['mask']\n","    batch_size = tf.shape(query)[0]\n","\n","    # 1. WQ, WK, WV에 해당하는 밀집층 지나기\n","    # q : (batch_size, query의 문장 길이, d_model)\n","    # k : (batch_size, key의 문장 길이, d_model)\n","    # v : (batch_size, value의 문장 길이, d_model)\n","    # 참고) 인코더(k, v)-디코더(q) 어텐션에서는 query 길이와 key, value의 길이는 다를 수 있다.\n","    query = self.query_dense(query)\n","    key = self.key_dense(key)\n","    value = self.value_dense(value)\n","\n","    # 2. 헤드 나누기\n","    # q : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n","    # k : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n","    # v : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n","    query = self.split_heads(query, batch_size)\n","    key = self.split_heads(key, batch_size)\n","    value = self.split_heads(value, batch_size)\n","\n","    # 3. 스케일드 닷 프로덕트 어텐션. 앞서 구현한 함수 사용.\n","    # (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n","    scaled_attention, _ = scaled_dot_product_attention(query, key, value, mask)\n","    # (batch_size, query의 문장 길이, num_heads, d_model/num_heads)\n","    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n","\n","    # 4. 헤드 연결(concatenate)하기\n","    # (batch_size, query의 문장 길이, d_model)\n","    concat_attention = tf.reshape(scaled_attention,\n","                                  (batch_size, -1, self.d_model))\n","\n","    # 5. WO에 해당하는 밀집층 지나기\n","    # (batch_size, query의 문장 길이, d_model)\n","    outputs = self.dense(concat_attention)\n","\n","    return outputs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aWzQ7UaUitu6"},"source":["# 아래 멀티-헤드 어텐션 부분에서 query, key, value가 전부 같으므로 \n","# 셀프 어텐션을 이용하게 되는 것.\n","# 셀프 어텐션이 아닐 경우에는, 해당 부분을 수정해주면 된다.\n","\n","def encoder_layer(dff, d_model, num_heads, dropout, name=\"encoder_layer\"):\n","  inputs = Input(shape=(max_len, d_model), name=\"inputs_layer\")\n","\n","  # 인코더는 패딩 마스크 사용\n","  padding_mask = Input(shape=(1, 1, None), name=\"padding_mask\")\n","\n","  # 멀티-헤드 어텐션 (첫번째 서브층 / 셀프 어텐션)\n","  attention = MultiHeadAttention(\n","      d_model, num_heads, name=\"attention\")({\n","          'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V\n","          'mask': padding_mask # 패딩 마스크 사용\n","      })\n","\n","  # 드롭아웃 + 잔차 연결과 층 정규화\n","  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n","  attention = tf.keras.layers.LayerNormalization(\n","      epsilon=1e-6)(inputs + attention)\n","\n","  # 포지션 와이즈 피드 포워드 신경망 (두번째 서브층)\n","  outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention)\n","  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n","\n","  # 드롭아웃 + 잔차 연결과 층 정규화\n","  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n","  outputs = tf.keras.layers.LayerNormalization(\n","      epsilon=1e-6)(attention + outputs)\n","\n","  return tf.keras.Model(\n","      inputs=[inputs, padding_mask], outputs=outputs, name=name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SoutVfBni2UC"},"source":["# 아래는 셀프-어텐션 용 인코더\n","# 질문 분석에만 쓰이고, 이미지와 결합시킬 때는 약간 수정을 해주자.\n","\n","def encoder(vocab_size, num_layers, dff,\n","            d_model, num_heads, dropout,\n","            name=\"encoder\"):\n","  inputs = Input(shape=(max_len, d_model), name=\"inputs_enc\")\n","\n","  # 인코더는 패딩 마스크 사용\n","  padding_mask = Input(shape=(1, 1, None), name=\"padding_mask\")\n","\n","  outputs = Dropout(rate=dropout)(inputs)\n","\n","  # 인코더를 num_layers개 쌓기\n","  for i in range(num_layers):\n","    outputs = encoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n","        dropout=dropout, name=\"encoder_layer_{}\".format(i),\n","    )([outputs, padding_mask])\n","\n","  return tf.keras.Model(\n","      inputs=[inputs, padding_mask], outputs=outputs, name=name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7Lv1grPyi5Wv"},"source":["def loss_function(y_true, y_pred):\n","  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n","\n","  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n","      from_logits=True, reduction='none')(y_true, y_pred)\n","\n","  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n","  loss = tf.multiply(loss, mask)\n","\n","  return tf.reduce_mean(loss)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AJ4hknPAjC-u"},"source":["# 학습률을 조정해주는 함수\n","class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n","\n","  def __init__(self, d_model, warmup_steps=WARM_UP):\n","    super(CustomSchedule, self).__init__()\n","    self.d_model = d_model\n","    self.d_model = tf.cast(self.d_model, tf.float32)\n","    self.warmup_steps = warmup_steps\n","\n","  def get_config(self):\n","    config = {\n","    'd_model': self.d_model,\n","    'warmup_steps': self.warmup_steps,\n","\n","     }\n","    return config\n","\n","  def __call__(self, step):\n","    #arg1 = 0.001\n","    arg1 = step**-0.5\n","    # 초반 warm_up, attention mechanism 을 위함\n","    arg2 = step * (self.warmup_steps**-1.5)\n","\n","    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bcgTDEnJXsUv"},"source":["class CustomSchedule2(tf.keras.optimizers.schedules.LearningRateSchedule):\n","\n","  def __init__(self, d_model, warmup_steps=WARM_UP):\n","    super(CustomSchedule2, self).__init__()\n","    self.d_model = d_model\n","    self.d_model = tf.cast(self.d_model, tf.float32)\n","    self.warmup_steps = warmup_steps\n","\n","  def get_config(self):\n","    config = {\n","    'd_model': self.d_model,\n","    'warmup_steps': self.warmup_steps,\n","\n","     }\n","    return config\n","\n","  def __call__(self, step):\n","    #arg1 = 0.001\n","    arg1 = (step+34000)**-0.5\n","    # 초반 warm_up, attention mechanism 을 위함\n","    arg2 = (step+34000) * (self.warmup_steps**-1.5)\n","\n","    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":297},"id":"m6PxWiAw28Cl","executionInfo":{"status":"ok","timestamp":1625174833374,"user_tz":-540,"elapsed":3022,"user":{"displayName":"오세정","photoUrl":"","userId":"10647477815584692687"}},"outputId":"d71cf09c-2aa0-4548-a43b-9b9d00324af5"},"source":["sample_learning_rate = CustomSchedule2(d_model=256)\n","\n","plt.plot(sample_learning_rate(tf.range(100, dtype=tf.float32)))\n","plt.ylabel(\"Learning Rate\")\n","plt.xlabel(\"Train Step\")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Text(0.5, 0, 'Train Step')"]},"metadata":{"tags":[]},"execution_count":14},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"xw4Zy6h9kygF"},"source":["# txt 가 쿼리\n","# img 가 key + value\n","\n","def txtimg_encoder_layer(dff, d_model, num_heads, dropout, name='imgtxt_encoder_layer'):\n","  txtInput = Input(shape=(max_len, d_model), name=\"txtInputs_Query\")\n","  imgInput = Input(shape=(max_len, d_model), name=\"imgInputs_Key_Value\")\n","  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n","\n","  # 멀티-헤드 어텐션 (Query : Txt, Key = Value : Image)\n","  imgAttention = MultiHeadAttention(\n","    d_model, num_heads, name=\"img_txt_attention\")(inputs={\n","        'query': txtInput, 'key': imgInput, 'value': imgInput, # Q != K = V\n","        'mask': padding_mask # 패딩 마스크\n","    })\n","\n","  # 잔차 + 정규화\n","  imgAttention = Dropout(rate=dropout)(imgAttention)\n","  imgAttention = LayerNormalization(epsilon=1e-6)(imgAttention + txtInput)\n","\n","  # 포지션 와이즈 피드 포워드 신경망 (세번째 서브층)\n","  outputs = Dense(units=dff, activation='relu',kernel_regularizer=keras.regularizers.l2(0.001))(imgAttention)\n","  outputs = Dense(units=d_model)(outputs)\n","\n","  # 드롭아웃 + 잔차 연결과 층 정규화\n","  outputs = Dropout(rate=dropout)(outputs)\n","  outputs = LayerNormalization(epsilon=1e-6)(outputs + imgAttention)\n","\n","  return tf.keras.Model(inputs=[txtInput, imgInput, padding_mask],\n","      outputs=outputs,\n","      name=name)\n","  \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B2YKkTE4t1XD"},"source":["# txt가 쿼리\n","# img가 키와 value\n","\n","def txtimg_encoder(vocab_size, num_layers, dff,\n","            d_model, num_heads, dropout,\n","            name=\"txtimg_encoder\"):\n","  txtInput = Input(shape=(max_len, d_model, ), name=\"txt inputs\")\n","  imgInput = Input(shape=(max_len, d_model, ), name=\"img inputs\")\n","\n","  # 인코더는 패딩 마스크 사용\n","  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n","\n","  outputs = tf.keras.layers.Dropout(rate=dropout)(txtInput)\n","\n","  # 인코더를 num_layers개 쌓기\n","  for i in range(num_layers):\n","    outputs = txtimg_encoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n","        dropout=dropout, name=\"txtimg_encoder_layer_{}\".format(i),\n","    )([outputs, imgInput ,padding_mask])\n","\n","  return tf.keras.Model(\n","      inputs=[txtInput, imgInput, padding_mask], outputs=outputs, name=name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FEh7xMKUqdGV"},"source":["# img 가 쿼리\n","# txt 가 key + value\n","\n","def imgtxt_encoder_layer(dff, d_model, num_heads, dropout, name='imgtxt_encoder_layer'):\n","  imgInput = Input(shape=(max_len, d_model), name=\"imgInputs_Query\")\n","  txtInput = Input(shape=(max_len, d_model), name=\"txtInputs_KeyValue\")\n","\n","  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n","\n","  # 멀티-헤드 어텐션 (Query : Txt, Key = Value : Image)\n","  txtAttention = MultiHeadAttention(\n","    d_model, num_heads, name=\"img_txt_attention\")(inputs={\n","        'query': imgInput, 'key': txtInput, 'value': txtInput, # Q != K = V\n","        'mask': padding_mask # 패딩 마스크\n","    })\n","\n","  # 잔차 + 정규화\n","  txtAttention = Dropout(rate=dropout)(txtAttention)\n","  txtAttention = LayerNormalization(epsilon=1e-6)(txtAttention + imgInput)\n","\n","  # 포지션 와이즈 피드 포워드 신경망 (세번째 서브층)\n","  outputs = Dense(units=dff, activation='relu',kernel_regularizer=keras.regularizers.l2(0.001))(txtAttention)\n","  outputs = Dense(units=d_model)(outputs)\n","\n","  # 드롭아웃 + 잔차 연결과 층 정규화\n","  outputs = Dropout(rate=dropout)(outputs)\n","  outputs = LayerNormalization(epsilon=1e-6)(outputs + txtAttention)\n","\n","  return tf.keras.Model(inputs=[imgInput, txtInput, padding_mask],\n","      outputs=outputs,\n","      name=name)\n","  \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OWwLBl-juKY3"},"source":["# img가 쿼리\n","# txt가 키와 value\n","\n","def imgtxt_encoder(vocab_size, num_layers, dff,\n","            d_model, num_heads, dropout,\n","            name=\"imgtxt_encoder\"):\n","  imgInput = Input(shape=(max_len, d_model,), name=\"img inputs\")\n","  txtInput = Input(shape=(max_len, d_model,), name=\"txt inputs\")\n","  # 인코더는 패딩 마스크 사용\n","  padding_mask = Input(shape=(1, 1, None), name=\"padding_mask\")\n","\n","  outputs = Dropout(rate=dropout)(imgInput)\n","\n","  # 인코더를 num_layers개 쌓기\n","  for i in range(num_layers):\n","    outputs = imgtxt_encoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n","        dropout=dropout, name=\"imgtxt_encoder_layer_{}\".format(i),\n","    )([outputs, txtInput ,padding_mask])\n","\n","  return Model(\n","      inputs=[imgInput, txtInput, padding_mask], outputs=outputs, name=name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1YdcmmM5-cXD"},"source":["def create_padding_mask(x):\n","  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n","  # (batch_size, 1, 1, key의 문장 길이)\n","  return mask[:, tf.newaxis, tf.newaxis, :]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zKzMos59jVsa"},"source":["# X는 train_data (image, question, answer)\n","# batch_size : BATCH_SIZE\n","# target_size : 이미지 크기\n","# shuffle : 셔플\n","\n","class DataGenerator(Sequence):\n","  def __init__(self, X, tokenizer, vocab_size, batch_size, target_size = (224,224), shuffle = True):\n","    self.X = X\n","    self.length = len(X)\n","    self.batch_size = batch_size\n","    self.target_size = target_size\n","    self.shuffle = shuffle\n","    self.tokenizer = tokenizer\n","    self.vocab_size = vocab_size\n","    self.on_epoch_end()\n","  \n","  def on_epoch_end(self):\n","    self.indexes = np.arange(self.length)\n","    if self.shuffle:\n","      np.random.shuffle(self.indexes)\n","\n","  def __len__(self):\n","    return int(np.floor(self.length / self.batch_size))\n","\n","  def __data_generation(self, i):  \n","    filepath = './images/' + self.X.iloc[i]['image']\n","    img = Image.open(filepath)\n","    img.draft('RGB', (224,224))\n","    img = img.resize(self.target_size, Image.NEAREST)\n","    img = np.array(img)\n","    img = img / 255.0\n","\n","    tokenized = self.tokenizer.tokenize(self.X.iloc[i]['question'])\n","    question = self.tokenizer.convert_tokens_to_ids(tokenized)\n","\n","    self.tokenizer.add_tokens(self.X.iloc[i]['answer'])\n","    answer = self.tokenizer.convert_tokens_to_ids(self.X.iloc[i]['answer'])\n","\n","    return img, question, answer\n","\n","  def __getitem__(self, index):\n","    img_data = np.empty((0,224,224,3))\n","    quest_data = []\n","    ans_data = []\n","    indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n","\n","    for i in indexes:\n","      img, question, answer = self.__data_generation(i)\n","      img_data = np.append(img_data, [img], axis=0)\n","      quest_data.append(question)\n","      ans_data.append(answer)\n","\n","    quest_data = sequence.pad_sequences(quest_data, maxlen=max_len, padding='post')\n","    ans_data = to_categorical(ans_data, num_classes = self.vocab_size)\n","\n","    return [quest_data, img_data], ans_data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WapiPi8ciWJJ"},"source":["# X는 train_data (image, question, answer)\n","# batch_size : BATCH_SIZE\n","# target_size : 이미지 크기\n","# shuffle : 셔플\n","\n","class DataGenerator_test(Sequence):\n","  def __init__(self, X, tokenizer, vocab_size, batch_size, target_size = (224,224), shuffle = True):\n","    self.X = X\n","    self.length = len(X)\n","    self.batch_size = batch_size\n","    self.target_size = target_size\n","    self.shuffle = shuffle\n","    self.tokenizer = tokenizer\n","    self.vocab_size = vocab_size\n","    self.on_epoch_end()\n","  \n","  def on_epoch_end(self):\n","    self.indexes = np.arange(self.length)\n","    if self.shuffle:\n","      np.random.shuffle(self.indexes)\n","\n","  def __len__(self):\n","    return int(np.floor(self.length / self.batch_size))\n","\n","  def __data_generation(self, i):  \n","    filepath = './test/images/' + self.X.iloc[i]['image']\n","    img = Image.open(filepath)\n","    img.draft('RGB', (224,224))\n","    img = img.resize(self.target_size, Image.NEAREST)\n","    img = np.array(img)\n","    img = img / 255.0\n","\n","    tokenized = self.tokenizer.tokenize(self.X.iloc[i]['question'])\n","    question = self.tokenizer.convert_tokens_to_ids(tokenized)\n","\n","    return img, question\n","\n","  def __getitem__(self, index):\n","    img_data = np.empty((0,224,224,3))\n","    quest_data = []\n","    indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n","\n","    for i in indexes:\n","      img, question = self.__data_generation(i)\n","      img_data = np.append(img_data, [img], axis=0)\n","      quest_data.append(question)\n","\n","    quest_data = sequence.pad_sequences(quest_data, maxlen=max_len, padding='post')\n","\n","    return [quest_data, img_data]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CVBYOc5lcj_L"},"source":["###데이터 제너레이터"]},{"cell_type":"code","metadata":{"id":"Gv5v0vXIRrqa","colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["68dd1d8e159146e98c144acf35e2bab1","37b6d1cca09549ceb8278636f2b4b356","51bb95d44623466daed0cf03e25041c4","41083dd4bee241c1a5ce0da28286973f","817f53b566f5421aa53c476eeea5e224","9d0bade193814c9aa03a485fc0f57e59","3dd0a01725b84a118323ad19158c46ef","205afb5956fe41058f03174a73a4767e","ea1dc37ad4ba499bbc53c8bee63490ac","e4712765df274b2093c14959a004fe45","295fbb3c460f41f796619b6204325230","c149e076482645b7adecc880ddc06ff9","d1e0389644974136b9fe8b3a17d142d7","fe8dcc8ff69b40ef9e81fcacf8f66fb2","38f85c08fffe44e5a7caf76cb3918ae0","685d729ea887406abfc48a37c45d5514","3be7b74b4f66490185dff074174fc07b","a98625ea41554d33a09cfd28a96e91f0","dedda69195744f0993a41cc1fe051069","f325185911dd4efe83d212180c4c45cb","ec99a776e6d1419f97c89cc023aa17d9","2021c34c62c44297b4958e9092666cc5","59498d3f9d37418f97eba8de0fc1693e","cbbf22fdde3647daa2d3d7dfe0777299"]},"executionInfo":{"status":"ok","timestamp":1625174839210,"user_tz":-540,"elapsed":5581,"user":{"displayName":"오세정","photoUrl":"","userId":"10647477815584692687"}},"outputId":"a1f8968d-23d5-4f97-c9ed-e0e641818977"},"source":["train_data = pd.read_csv('./drive/MyDrive/vqa/train.csv')\n","train_data.drop(['category'], axis=1,inplace=True)\n","\n","tokenizer = get_tokenizer()\n","\n","train_data, valid_data, train_y, valid_y = train_test_split(train_data, train_data['answer'], test_size=0.01, random_state=77)\n","\n","train_generator = DataGenerator(train_data, tokenizer=tokenizer, vocab_size=VOCAB_SIZE, \n","                  batch_size=BATCH_SIZE,\n","                  target_size = (TARGET_SIZE, TARGET_SIZE),\n","                  shuffle=True)\n","\n","valid_generator = DataGenerator(valid_data, tokenizer=tokenizer, vocab_size=VOCAB_SIZE, \n","                  batch_size=BATCH_SIZE,\n","                  target_size = (TARGET_SIZE, TARGET_SIZE),\n","                  shuffle=True)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"68dd1d8e159146e98c144acf35e2bab1","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=371391.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ea1dc37ad4ba499bbc53c8bee63490ac","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=77779.0, style=ProgressStyle(descriptio…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3be7b74b4f66490185dff074174fc07b","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=51.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gK0wd-rko8KY"},"source":["###모델링\n"]},{"cell_type":"code","metadata":{"id":"T6sIjmMKPWUr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625174856845,"user_tz":-540,"elapsed":17637,"user":{"displayName":"오세정","photoUrl":"","userId":"10647477815584692687"}},"outputId":"9eba9b63-f6b8-48da-d73c-89476c6d85b8"},"source":["# 여기서 문장의 길이를 max_len으로 맞춰주자.\n","txtInput = Input(shape=(max_len, ), name='text_input')\n","imgInput = Input(shape=(224, 224, 3, ), name='img_input')\n","\n","padding_mask = tf.keras.layers.Lambda(\n","      create_padding_mask, output_shape=(1, 1, None),\n","      name='enc_padding_mask')(txtInput)\n","\n","# 텍스트 입력 후 Transformer Encoder 통과\n","# 형태소가 나누어져서 각 단어마다 정수 인코딩이 된 상태라고 가정.(토큰화 완료)\n","# 사전 훈련된 한국어 임베딩 모델....있나?\n","# tokenizer은 koBERT의 토크나이저 사용\n","# 임베딩은 pre-trained를 사용하지 않고 질문에서 학습\n","\n","embedding_layer = TokenAndPositionEmbedding(max_len, VOCAB_SIZE, d_model)\n","\n","# text의 각 단어에 512차원의 임베딩완료(임베딩 + 포지션)\n","txt = embedding_layer(txtInput)\n","\n","# 멀티헤드어텐션 + FFNN 네트워크, num_layers 만큼 존재\n","# 입력 : txt : (None, 40, 512)\n","# 출력 : txtOutput, (None, 40, 512)\n","txtOutput = encoder(VOCAB_SIZE, num_layers=num_layers, dff=dff, \n","                     d_model=d_model, num_heads=num_heads,\n","                     dropout=dropout)([txt, padding_mask])\n","\n","# 이미지 입력 후 CNN 통과\n","# 출력 : imgOutput, (None, 40, 512)\n","img = Conv2D(64, (3,3), padding='same', name='block1_conv1', activation='relu')(imgInput)\n","img = Conv2D(64, (3,3), padding='same', name='block1_conv2', activation='relu')(img)\n","img = MaxPooling2D((4,4), name='block1_pool')(img)\n","img = Conv2D(128, (3,3), padding='same', name='block2_conv1', activation='relu')(img)\n","img = Conv2D(128, (3,3), padding='same', name='block2_conv2', activation='relu')(img)\n","img = MaxPooling2D((4,4), name='block2_pool')(img)\n","img = Conv2D(256, (3,3), padding='same', name='block3_conv1', activation='relu')(img)\n","img = Conv2D(256, (3,3), padding='same', name='block3_conv2', activation='relu')(img)\n","img = MaxPooling2D((4,4), name='block3_pool')(img)\n","#img = Conv2D(512, (3,3), padding='same', name='block4_conv1', activation='relu')(img)\n","#img = Conv2D(512, (3,3), padding='same', name='block4_conv2', activation='relu')(img)\n","#img = MaxPooling2D((4,4), name='block4_pool')(img)\n","#img = Conv2D(1024, (3,3), padding='same', name='block5_conv1', activation='relu')(img)\n","#img = Conv2D(1024, (3,3), padding='same', name='block5_conv2', activation='relu')(img)\n","#img = MaxPooling2D((4,4), name='block5_pool')(img)\n","img = Flatten()(img)\n","img = Dense(d_model, activation='relu')(img)\n","\n","#imgOutput = img\n","#for i in range(max_len-1):\n","#  imgOutput = concatenate([imgOutput, img])\n","#imgOutput = Reshape((max_len,d_model))(imgOutput)\n","img = Reshape([1, d_model])(img)\n","ones = tf.ones([1, max_len, 1])\n","imgOutput = tf.matmul(ones, img)\n","\n","\n","imgAttention_1 = txtimg_encoder(vocab_size=VOCAB_SIZE, num_layers = num_layers, dff=dff, d_model=d_model, num_heads=num_heads, \n","                     dropout=dropout, name=\"txtimg_encoder_1\")([txtOutput, imgOutput, padding_mask])\n","\n","txtAttention = imgtxt_encoder(vocab_size=VOCAB_SIZE, num_layers = num_layers, dff=dff, d_model=d_model, num_heads=num_heads,\n","                              dropout=dropout, name=\"imgtxt_encoder_1\")([imgAttention_1, txtOutput, padding_mask])\n","\n","imgAttention_2 = txtimg_encoder(vocab_size=VOCAB_SIZE, num_layers = num_layers, dff=dff, d_model=d_model, num_heads=num_heads, \n","                     dropout=dropout, name=\"txtimg_encoder_2\")([txtAttention, imgAttention_1, padding_mask])\n","                  \n","outputs = imgtxt_encoder(vocab_size=VOCAB_SIZE, num_layers = num_layers, dff=dff, d_model=d_model, num_heads=num_heads,\n","                              dropout=dropout, name=\"imgtxt_encoder_2\")([imgAttention_2, txtAttention, padding_mask])\n","\n","outputs = Flatten()(outputs)\n","txtFlat = Flatten()(txtOutput)\n","imgFlat = Flatten()(imgOutput)\n","outputs = concatenate([outputs , txtFlat, imgFlat], axis=-1)\n","# outputs = Flatten()(imgAttention)\n","outputs = Dropout(dropout)(outputs)\n","outputs = Dense(VOCAB_SIZE, activation='softmax')(outputs)\n","\n","\n","\n","model = Model(inputs = [txtInput, imgInput], outputs = outputs)\n","\n","#learning_rate = CustomSchedule(d_model)\n","learning_rate = CustomSchedule2(d_model)\n","optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, beta_1 = 0.9, beta_2 = 0.98, epsilon=1e-9)\n","#optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate, nesterov=True, momentum=0.9)\n","#optimizer = tf.keras.optimizers.Nadam(learning_rate=0.001)\n","# 아래는 learning_rate 고정\n","#optimizer = tf.keras.optimizers.Adam(learning_rate = 0.003, beta_1 = 0.9, beta_2 = 0.98, epsilon=1e-9)\n","\n","model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n","\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","img_input (InputLayer)          [(None, 224, 224, 3) 0                                            \n","__________________________________________________________________________________________________\n","block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        img_input[0][0]                  \n","__________________________________________________________________________________________________\n","block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n","__________________________________________________________________________________________________\n","block1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           block1_conv2[0][0]               \n","__________________________________________________________________________________________________\n","block2_conv1 (Conv2D)           (None, 56, 56, 128)  73856       block1_pool[0][0]                \n","__________________________________________________________________________________________________\n","block2_conv2 (Conv2D)           (None, 56, 56, 128)  147584      block2_conv1[0][0]               \n","__________________________________________________________________________________________________\n","block2_pool (MaxPooling2D)      (None, 14, 14, 128)  0           block2_conv2[0][0]               \n","__________________________________________________________________________________________________\n","block3_conv1 (Conv2D)           (None, 14, 14, 256)  295168      block2_pool[0][0]                \n","__________________________________________________________________________________________________\n","block3_conv2 (Conv2D)           (None, 14, 14, 256)  590080      block3_conv1[0][0]               \n","__________________________________________________________________________________________________\n","block3_pool (MaxPooling2D)      (None, 3, 3, 256)    0           block3_conv2[0][0]               \n","__________________________________________________________________________________________________\n","flatten (Flatten)               (None, 2304)         0           block3_pool[0][0]                \n","__________________________________________________________________________________________________\n","text_input (InputLayer)         [(None, 20)]         0                                            \n","__________________________________________________________________________________________________\n","dense_60 (Dense)                (None, 256)          590080      flatten[0][0]                    \n","__________________________________________________________________________________________________\n","token_and_position_embedding (T (None, 20, 256)      2565120     text_input[0][0]                 \n","__________________________________________________________________________________________________\n","enc_padding_mask (Lambda)       (None, 1, 1, 20)     0           text_input[0][0]                 \n","__________________________________________________________________________________________________\n","reshape (Reshape)               (None, 1, 256)       0           dense_60[0][0]                   \n","__________________________________________________________________________________________________\n","encoder (Functional)            (None, 20, 256)      5271040     token_and_position_embedding[0][0\n","                                                                 enc_padding_mask[0][0]           \n","__________________________________________________________________________________________________\n","tf.linalg.matmul (TFOpLambda)   (None, 20, 256)      0           reshape[0][0]                    \n","__________________________________________________________________________________________________\n","txtimg_encoder_1 (Functional)   (None, 20, 256)      5271040     encoder[0][0]                    \n","                                                                 tf.linalg.matmul[0][0]           \n","                                                                 enc_padding_mask[0][0]           \n","__________________________________________________________________________________________________\n","imgtxt_encoder_1 (Functional)   (None, 20, 256)      5271040     txtimg_encoder_1[0][0]           \n","                                                                 encoder[0][0]                    \n","                                                                 enc_padding_mask[0][0]           \n","__________________________________________________________________________________________________\n","txtimg_encoder_2 (Functional)   (None, 20, 256)      5271040     imgtxt_encoder_1[0][0]           \n","                                                                 txtimg_encoder_1[0][0]           \n","                                                                 enc_padding_mask[0][0]           \n","__________________________________________________________________________________________________\n","imgtxt_encoder_2 (Functional)   (None, 20, 256)      5271040     txtimg_encoder_2[0][0]           \n","                                                                 imgtxt_encoder_1[0][0]           \n","                                                                 enc_padding_mask[0][0]           \n","__________________________________________________________________________________________________\n","flatten_1 (Flatten)             (None, 5120)         0           imgtxt_encoder_2[0][0]           \n","__________________________________________________________________________________________________\n","flatten_2 (Flatten)             (None, 5120)         0           encoder[0][0]                    \n","__________________________________________________________________________________________________\n","flatten_3 (Flatten)             (None, 5120)         0           tf.linalg.matmul[0][0]           \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 15360)        0           flatten_1[0][0]                  \n","                                                                 flatten_2[0][0]                  \n","                                                                 flatten_3[0][0]                  \n","__________________________________________________________________________________________________\n","dropout_105 (Dropout)           (None, 15360)        0           concatenate[0][0]                \n","__________________________________________________________________________________________________\n","dense_301 (Dense)               (None, 10000)        153610000   dropout_105[0][0]                \n","==================================================================================================\n","Total params: 184,265,808\n","Trainable params: 184,265,808\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"O5_h9Mhd7Xn4"},"source":["model.load_weights('./drive/MyDrive/vqa/8_256_512_10_32_5_encoderlayer_2.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xe8L145LnJNb","colab":{"base_uri":"https://localhost:8080/","height":194},"executionInfo":{"status":"ok","timestamp":1625204459112,"user_tz":-540,"elapsed":8198946,"user":{"displayName":"오세정","photoUrl":"","userId":"10647477815584692687"}},"outputId":"a5c6f05e-ddc4-4ab4-a160-b7018ebe6424"},"source":["# text_data : 질문 데이터\n","# img_data : 이미지 데이터\n","# answers : 정답 데이터 (인코딩 된)\n","EPOCHS = 4\n","history = model.fit(\n","    x = train_generator, \n","    epochs = EPOCHS,\n","    validation_data = valid_generator,\n","    workers = 6\n","    # callbacks = callback_list\n",")\n","\n","filename = './8_256_512_10_32_15_encoderlayer_2'\n","# 파일 이름 형식\n","# layer(트랜스포머 층 개수)_dmodel(임베딩벡터 크기)_dff(피드포워드신경망크기)_numhead(멀티 헤드 개수)\n","# _img(conv-maxpooling 층 개수)(한 층당 conv 층개수)_epoch(에포크 횟수)\n","\n","# 드라이브에 있는 test.csv를 업로드 하고 실행\n","test_data = pd.read_csv('./drive/MyDrive/vqa/test.csv')\n","test_generator = DataGenerator_test(test_data, tokenizer=tokenizer, vocab_size=VOCAB_SIZE, \n","                  batch_size=1,\n","                  target_size = (TARGET_SIZE, TARGET_SIZE),\n","                  shuffle=False)\n","\n","outputs = model.predict(x = test_generator, workers = 6, verbose = 1)\n","output = np.argmax(outputs, axis = 1)\n","test_answer = tokenizer.convert_ids_to_tokens(output)\n","data = {\n","    'ID':test_data['ID'],\n","    'answer':test_answer,\n","}\n","submission = pd.DataFrame(data)\n","submission.set_index('ID',inplace=True)\n","submission.to_csv(filename + '.csv')\n","files.download(filename + '.csv')\n","model.save_weights(filename + '.h5')\n","files.download(filename + '.h5')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/4\n","6951/6951 [==============================] - 6880s 978ms/step - loss: 1.0640 - accuracy: 0.6238 - val_loss: 1.0357 - val_accuracy: 0.6239\n","Epoch 2/4\n","6951/6951 [==============================] - 6925s 995ms/step - loss: 1.0150 - accuracy: 0.6355 - val_loss: 1.0262 - val_accuracy: 0.6340\n","Epoch 3/4\n","6951/6951 [==============================] - 7033s 1s/step - loss: 0.9995 - accuracy: 0.6399 - val_loss: 1.0216 - val_accuracy: 0.6313\n","Epoch 4/4\n","6951/6951 [==============================] - 7079s 1s/step - loss: 0.9881 - accuracy: 0.6441 - val_loss: 1.0292 - val_accuracy: 0.6296\n","22131/22131 [==============================] - 1668s 75ms/step\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_98a2a92a-fee7-460f-b78d-219855cb015f\", \"8_256_512_10_32_15_encoderlayer_2.csv\", 206743)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_8e403520-57a5-4b1d-bde2-05ad91cc42a8\", \"8_256_512_10_32_15_encoderlayer_2.h5\", 737841288)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}}]}]}